{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensuring Consistency in Multi-source Data Integration\n",
    "\n",
    "**Description**: Validate the integration of two datasets `products_A.csv` and `products_B.csv` . Ensure consistency in product \"category\" information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'products_A.csv' not found. Creating a dummy DataFrame.\n",
      "Error: 'products_B.csv' not found. Creating a dummy DataFrame.\n",
      "\n",
      "--- DataFrames Loaded ---\n",
      "products_A.head():\n",
      "  product_id product_name     category  price_A\n",
      "0       P001       Laptop  Electronics     1200\n",
      "1       P002        Mouse  Peripherals       25\n",
      "2       P003     Keyboard  Peripherals       75\n",
      "3       P004      Monitor  Electronics      300\n",
      "4       P005       Webcam  Peripherals       50\n",
      "\n",
      "products_B.head():\n",
      "  product_id product_name     category  stock_B\n",
      "0       P001       Laptop  Electronics       50\n",
      "1       P002        Mouse   Peripheral      100\n",
      "2       P003     Keyboard  Peripherals       75\n",
      "3       P004      Monitor    Computers       30\n",
      "4       P006      Printer  Peripherals       20\n",
      "\n",
      "--- Merged DataFrame (Partial View) ---\n",
      "  product_id product_name_A   category_A  price_A product_name_B   category_B  \\\n",
      "0       P001         Laptop  Electronics   1200.0         Laptop  Electronics   \n",
      "1       P002          Mouse  Peripherals     25.0          Mouse   Peripheral   \n",
      "2       P003       Keyboard  Peripherals     75.0       Keyboard  Peripherals   \n",
      "3       P004        Monitor  Electronics    300.0        Monitor    Computers   \n",
      "4       P005         Webcam  Peripherals     50.0            NaN          NaN   \n",
      "\n",
      "   stock_B  \n",
      "0     50.0  \n",
      "1    100.0  \n",
      "2     75.0  \n",
      "3     30.0  \n",
      "4      NaN  \n",
      "\n",
      "--- Products with Inconsistent Categories ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['product_name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Products with Inconsistent Categories ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inconsistent_categories\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43minconsistent_categories\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcommon_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduct_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory_A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategory_B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo direct category inconsistencies found for common products.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['product_name'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "try:\n",
    "    df_A = pd.read_csv(\"products_A.csv\")\n",
    "    print(\"products_A.csv loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'products_A.csv' not found. Creating a dummy DataFrame.\")\n",
    "    df_A = pd.DataFrame({\n",
    "        'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "        'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam'],\n",
    "        'category': ['Electronics', 'Peripherals', 'Peripherals', 'Electronics', 'Peripherals'],\n",
    "        'price_A': [1200, 25, 75, 300, 50]\n",
    "    })\n",
    "\n",
    "try:\n",
    "    df_B = pd.read_csv(\"products_B.csv\")\n",
    "    print(\"products_B.csv loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'products_B.csv' not found. Creating a dummy DataFrame.\")\n",
    "    df_B = pd.DataFrame({\n",
    "        'product_id': ['P001', 'P002', 'P003', 'P004', 'P006'],\n",
    "        'product_name': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Printer'],\n",
    "        'category': ['Electronics', 'Peripheral', 'Peripherals', 'Computers', 'Peripherals'], # Note: 'Peripheral' vs 'Peripherals', 'Computers' vs 'Electronics'\n",
    "        'stock_B': [50, 100, 75, 30, 20]\n",
    "    })\n",
    "\n",
    "print(\"\\n--- DataFrames Loaded ---\")\n",
    "print(\"products_A.head():\")\n",
    "print(df_A.head())\n",
    "print(\"\\nproducts_B.head():\")\n",
    "print(df_B.head())\n",
    "\n",
    "# --- 2. Identify Common Keys ---\n",
    "# Assuming 'product_id' is the primary key for joining.\n",
    "common_key = 'product_id'\n",
    "\n",
    "# --- 3. Merge Data ---\n",
    "# Using an outer merge to include all products from both datasets.\n",
    "# We'll keep both 'category' columns to compare them.\n",
    "merged_df = pd.merge(df_A, df_B, on=common_key, how='outer', suffixes=('_A', '_B'))\n",
    "\n",
    "print(\"\\n--- Merged DataFrame (Partial View) ---\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# --- 4. Compare 'category' Information and 5. Identify Inconsistencies ---\n",
    "# Convert categories to a consistent case (e.g., lowercase) and strip whitespace\n",
    "merged_df['category_A_clean'] = merged_df['category_A'].str.lower().str.strip()\n",
    "merged_df['category_B_clean'] = merged_df['category_B'].str.lower().str.strip()\n",
    "\n",
    "# Identify inconsistencies where both categories exist but are different\n",
    "inconsistent_categories = merged_df[\n",
    "    (merged_df['category_A_clean'].notna()) &\n",
    "    (merged_df['category_B_clean'].notna()) &\n",
    "    (merged_df['category_A_clean'] != merged_df['category_B_clean'])\n",
    "]\n",
    "\n",
    "print(\"\\n--- Products with Inconsistent Categories ---\")\n",
    "if not inconsistent_categories.empty:\n",
    "    print(inconsistent_categories[[common_key, 'product_name', 'category_A', 'category_B']])\n",
    "else:\n",
    "    print(\"No direct category inconsistencies found for common products.\")\n",
    "\n",
    "# Also check for products present in one dataset but not the other,\n",
    "# which might imply missing category information or new products.\n",
    "products_only_A = merged_df[merged_df['category_B'].isna() & merged_df['category_A'].notna()]\n",
    "products_only_B = merged_df[merged_df['category_A'].isna() & merged_df['category_B'].notna()]\n",
    "\n",
    "if not products_only_A.empty:\n",
    "    print(\"\\n--- Products found only in products_A (missing category in B) ---\")\n",
    "    print(products_only_A[[common_key, 'product_name', 'category_A']])\n",
    "\n",
    "if not products_only_B.empty:\n",
    "    print(\"\\n--- Products found only in products_B (missing category in A) ---\")\n",
    "    print(products_only_B[[common_key, 'product_name', 'category_B']])\n",
    "\n",
    "# --- 6. Analyze and Resolve (Example of a simple resolution strategy) ---\n",
    "# For demonstration, let's create a 'final_category' column.\n",
    "# Resolution strategy:\n",
    "# 1. If categories are consistent, use that category.\n",
    "# 2. If inconsistent, prioritize category from A (or B, or flag for review).\n",
    "# 3. If category is only in A or B, use that category.\n",
    "\n",
    "merged_df['final_category'] = merged_df['category_A_clean']\n",
    "\n",
    "# If category_A_clean is NaN, but category_B_clean is not NaN, use category_B_clean\n",
    "merged_df.loc[merged_df['category_A_clean'].isna(), 'final_category'] = merged_df['category_B_clean']\n",
    "\n",
    "# For inconsistent cases, we need a rule. Let's say we prioritize 'category_A'\n",
    "# You would define your business logic here.\n",
    "# For this example, if there's an inconsistency, we'll keep the category from A.\n",
    "# If you wanted to flag them, you could add a 'consistency_flag' column.\n",
    "merged_df['consistency_flag'] = 'Consistent'\n",
    "merged_df.loc[\n",
    "    (merged_df['category_A_clean'].notna()) &\n",
    "    (merged_df['category_B_clean'].notna()) &\n",
    "    (merged_df['category_A_clean'] != merged_df['category_B_clean']),\n",
    "    'consistency_flag'\n",
    "] = 'Inconsistent - Needs Review'\n",
    "\n",
    "print(\"\\n--- Merged DataFrame with Final Category and Consistency Flag ---\")\n",
    "print(merged_df[[common_key, 'product_name', 'category_A', 'category_B', 'final_category', 'consistency_flag']].head(10))\n",
    "\n",
    "print(\"\\nSummary of Consistency Flags:\")\n",
    "print(merged_df['consistency_flag'].value_counts())\n",
    "\n",
    "# You can now save this reconciled DataFrame\n",
    "# merged_df.to_csv(\"integrated_products_with_consistent_categories.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
