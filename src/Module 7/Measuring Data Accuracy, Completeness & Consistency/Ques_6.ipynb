{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture to Monitor Data Quality Over Time\n",
    "\n",
    "**Description**: Design a monitoring system in Python that checks and logs data quality metrics (accuracy, completeness) for a dataset over time.\n",
    "\n",
    "**Steps to follow:**\n",
    "1. Implement a Scheduled Script:\n",
    "    - Use schedule library to periodically run a script.\n",
    "2. Script to Calculate Metrics:\n",
    "    - For simplicity, use a function calculate_quality_metrics() that calculates and logs metrics such as missing rate or mismatch rate.\n",
    "3. Store Logs:\n",
    "    - Use Python's logging library to save these metrics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Data Quality Monitor is running. Press Ctrl+C to stop.\n",
      "Logged: transaction_id_missing_pct: 40.0% | amount_missing_pct: 20.0% | date_missing_pct: 20.0% | status_accuracy_pct: 80.0%\n",
      "Logged: transaction_id_missing_pct: 40.0% | amount_missing_pct: 20.0% | date_missing_pct: 20.0% | status_accuracy_pct: 80.0%\n",
      "Logged: transaction_id_missing_pct: 40.0% | amount_missing_pct: 20.0% | date_missing_pct: 20.0% | status_accuracy_pct: 80.0%\n",
      "Logged: transaction_id_missing_pct: 40.0% | amount_missing_pct: 20.0% | date_missing_pct: 20.0% | status_accuracy_pct: 100.0%\n",
      "Logged: transaction_id_missing_pct: 40.0% | amount_missing_pct: 20.0% | date_missing_pct: 20.0% | status_accuracy_pct: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# Install required library\n",
    "# If you're using Jupyter Notebook, uncomment the line below:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import schedule\n",
    "import time\n",
    "import random\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Set up logging\n",
    "# ----------------------------------------\n",
    "logging.basicConfig(\n",
    "    filename='data_quality.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Simulated data loading function\n",
    "# Replace this with pd.read_csv('your_data.csv') for real use\n",
    "# ----------------------------------------\n",
    "def load_data():\n",
    "    data = {\n",
    "        \"transaction_id\": [1001, 1002, None, 1004, None],\n",
    "        \"amount\": [200, None, 300, 400, 500],\n",
    "        \"date\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", None, \"2024-01-05\"],\n",
    "        \"status\": [\"Completed\", \"Failed\", \"Completed\", \"Completed\", random.choice([\"Failed\", None])]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Calculate quality metrics\n",
    "# ----------------------------------------\n",
    "def calculate_quality_metrics(df):\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: % missing in critical fields\n",
    "    critical_fields = ['transaction_id', 'amount', 'date']\n",
    "    for col in critical_fields:\n",
    "        missing_pct = df[col].isnull().mean() * 100\n",
    "        metrics[f\"{col}_missing_pct\"] = round(missing_pct, 2)\n",
    "\n",
    "    # Accuracy: status should be either 'Completed' or 'Failed'\n",
    "    valid_statuses = {'Completed', 'Failed'}\n",
    "    invalid_status_pct = (~df['status'].isin(valid_statuses)).mean() * 100\n",
    "    metrics['status_accuracy_pct'] = round(100 - invalid_status_pct, 2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Scheduled job to run the checks\n",
    "# ----------------------------------------\n",
    "def job():\n",
    "    df = load_data()\n",
    "    metrics = calculate_quality_metrics(df)\n",
    "    log_message = \" | \".join([f\"{key}: {value}%\" for key, value in metrics.items()])\n",
    "    logging.info(f\"Data Quality Metrics - {log_message}\")\n",
    "    print(f\"Logged: {log_message}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 5: Schedule job to run every minute\n",
    "# ----------------------------------------\n",
    "schedule.every(1).minutes.do(job)\n",
    "\n",
    "print(\"⏳ Data Quality Monitor is running. Press Ctrl+C to stop.\")\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "# Install required library\n",
    "# If you're using Jupyter Notebook, uncomment the line below:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import schedule\n",
    "import time\n",
    "import random\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 1: Set up logging\n",
    "# ----------------------------------------\n",
    "logging.basicConfig(\n",
    "    filename='data_quality.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 2: Simulated data loading function\n",
    "# Replace this with pd.read_csv('your_data.csv') for real use\n",
    "# ----------------------------------------\n",
    "def load_data():\n",
    "    data = {\n",
    "        \"transaction_id\": [1001, 1002, None, 1004, None],\n",
    "        \"amount\": [200, None, 300, 400, 500],\n",
    "        \"date\": [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", None, \"2024-01-05\"],\n",
    "        \"status\": [\"Completed\", \"Failed\", \"Completed\", \"Completed\", random.choice([\"Failed\", None])]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 3: Calculate quality metrics\n",
    "# ----------------------------------------\n",
    "def calculate_quality_metrics(df):\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: % missing in critical fields\n",
    "    critical_fields = ['transaction_id', 'amount', 'date']\n",
    "    for col in critical_fields:\n",
    "        missing_pct = df[col].isnull().mean() * 100\n",
    "        metrics[f\"{col}_missing_pct\"] = round(missing_pct, 2)\n",
    "\n",
    "    # Accuracy: status should be either 'Completed' or 'Failed'\n",
    "    valid_statuses = {'Completed', 'Failed'}\n",
    "    invalid_status_pct = (~df['status'].isin(valid_statuses)).mean() * 100\n",
    "    metrics['status_accuracy_pct'] = round(100 - invalid_status_pct, 2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 4: Scheduled job to run the checks\n",
    "# ----------------------------------------\n",
    "def job():\n",
    "    df = load_data()\n",
    "    metrics = calculate_quality_metrics(df)\n",
    "    log_message = \" | \".join([f\"{key}: {value}%\" for key, value in metrics.items()])\n",
    "    logging.info(f\"Data Quality Metrics - {log_message}\")\n",
    "    print(f\"Logged: {log_message}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Step 5: Schedule job to run every minute\n",
    "# ----------------------------------------\n",
    "schedule.every(1).minutes.do(job)\n",
    "\n",
    "print(\"⏳ Data Quality Monitor is running. Press Ctrl+C to stop.\")\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
