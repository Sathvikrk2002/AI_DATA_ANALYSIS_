{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset with Missing Values:\n",
      "    Age   Income  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1   NaN  60000.0         5.0\n",
      "2  35.0      NaN         7.0\n",
      "3  40.0  80000.0         NaN\n",
      "4  50.0  90000.0        10.0\n",
      "\n",
      "Transformed Dataset (after Imputation + Scaling):\n",
      "        Age    Income  Experience\n",
      "0 -1.550434 -1.414214   -1.533930\n",
      "1  0.000000 -0.707107   -0.383482\n",
      "2 -0.310087  0.000000    0.383482\n",
      "3  0.310087  0.707107    0.000000\n",
      "4  1.550434  1.414214    1.533930\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Step 1: Sample dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, None, 35, 40, 50],\n",
    "    'Income': [50000, 60000, None, 80000, 90000],\n",
    "    'Experience': [2, 5, 7, None, 10]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Dataset with Missing Values:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: List of numerical columns\n",
    "numeric_features = ['Age', 'Income', 'Experience']\n",
    "\n",
    "# Step 3: Define transformer for numerical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),       # Fill missing values\n",
    "    ('scaler', StandardScaler())                       # Scale the features\n",
    "])\n",
    "\n",
    "# Step 4: Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features)\n",
    "])\n",
    "\n",
    "# Step 5: Apply the transformation\n",
    "processed_data = preprocessor.fit_transform(df)\n",
    "\n",
    "# Step 6: Convert to DataFrame for easy viewing\n",
    "processed_df = pd.DataFrame(processed_data, columns=numeric_features)\n",
    "\n",
    "print(\"\\nTransformed Dataset (after Imputation + Scaling):\")\n",
    "print(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "def impute_data(df, strategy='mean'):\n",
    "    \"\"\"\n",
    "    Impute missing values in a DataFrame using the specified strategy.\n",
    "    \"\"\"\n",
    "    imputer = SimpleImputer(strategy=strategy)\n",
    "    imputed_data = imputer.fit_transform(df)\n",
    "    return pd.DataFrame(imputed_data, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_data(df):\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    return pd.DataFrame(scaled_data, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def preprocess_data(df, numeric_features):\n",
    "    \"\"\"\n",
    "    Apply both imputation and scaling to numeric features.\n",
    "    \"\"\"\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "    \n",
    "    processed_data = preprocessor.fit_transform(df)\n",
    "    return pd.DataFrame(processed_data, columns=numeric_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "     Age   Income  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1   NaN  60000.0         5.0\n",
      "2  35.0      NaN         7.0\n",
      "3  40.0  80000.0         NaN\n",
      "4  50.0  90000.0        10.0\n",
      "\n",
      "Imputed:\n",
      "     Age   Income  Experience\n",
      "0  25.0  50000.0         2.0\n",
      "1  37.5  60000.0         5.0\n",
      "2  35.0  70000.0         7.0\n",
      "3  40.0  80000.0         6.0\n",
      "4  50.0  90000.0        10.0\n",
      "\n",
      "Scaled:\n",
      "         Age    Income  Experience\n",
      "0 -1.550434 -1.414214   -1.533930\n",
      "1  0.000000 -0.707107   -0.383482\n",
      "2 -0.310087  0.000000    0.383482\n",
      "3  0.310087  0.707107    0.000000\n",
      "4  1.550434  1.414214    1.533930\n",
      "\n",
      "Combined (Imputed + Scaled):\n",
      "         Age    Income  Experience\n",
      "0 -1.550434 -1.414214   -1.533930\n",
      "1  0.000000 -0.707107   -0.383482\n",
      "2 -0.310087  0.000000    0.383482\n",
      "3  0.310087  0.707107    0.000000\n",
      "4  1.550434  1.414214    1.533930\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'Age': [25, None, 35, 40, 50],\n",
    "    'Income': [50000, 60000, None, 80000, 90000],\n",
    "    'Experience': [2, 5, 7, None, 10]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define columns to transform\n",
    "numeric_columns = ['Age', 'Income', 'Experience']\n",
    "\n",
    "# Step-by-step usage\n",
    "imputed_df = impute_data(df[numeric_columns])\n",
    "scaled_df = scale_data(imputed_df)\n",
    "combined_df = preprocess_data(df, numeric_columns)\n",
    "\n",
    "print(\"Original:\\n\", df)\n",
    "print(\"\\nImputed:\\n\", imputed_df)\n",
    "print(\"\\nScaled:\\n\", scaled_df)\n",
    "print(\"\\nCombined (Imputed + Scaled):\\n\", combined_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
