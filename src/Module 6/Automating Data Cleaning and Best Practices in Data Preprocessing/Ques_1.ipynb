{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "    Task: Basic Pipeline with Scaling\n",
    "1. Objective: Create a pipeline that scales numerical features in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset with Pandas.\n",
    "    - Define a pipeline using Pipeline from sklearn.pipeline .\n",
    "    - Use StandardScaler to scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data (first 5 rows):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "\n",
      "Scaled Data (first 5 rows):\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444\n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
      "2          -1.385353          0.328414          -1.397064         -1.315444\n",
      "3          -1.506521          0.098217          -1.283389         -1.315444\n",
      "4          -1.021849          1.249201          -1.340227         -1.315444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load sample dataset (using Iris dataset here for demonstration)\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "print(\"Original Data (first 5 rows):\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Define a pipeline with StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Step 3: Apply pipeline to scale numerical features\n",
    "scaled_data = pipeline.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame for readability\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "\n",
    "print(\"\\nScaled Data (first 5 rows):\")\n",
    "print(scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Pipeline with Imputation\n",
    "1. Objective: Automate data cleaning by handling missing values.\n",
    "2. Steps:\n",
    "    - Load a dataset with missing values.\n",
    "    - Define a pipeline to use SimpleImputer for filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data with Missing Values:\n",
      "    Age   Income\n",
      "0  25.0  50000.0\n",
      "1  30.0  60000.0\n",
      "2   NaN  55000.0\n",
      "3  35.0      NaN\n",
      "4  40.0  65000.0\n",
      "\n",
      "Data after Imputation and Scaling:\n",
      "   Age  Income\n",
      "0 -1.5    -1.5\n",
      "1 -0.5     0.5\n",
      "2  0.0    -0.5\n",
      "3  0.5     0.0\n",
      "4  1.5     1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Create sample dataset with missing values for demonstration\n",
    "data = {\n",
    "    'Age': [25, 30, None, 35, 40],\n",
    "    'Income': [50000, 60000, 55000, None, 65000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Define a pipeline with SimpleImputer to fill missing values (e.g., mean) and then scale\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values with column mean\n",
    "    ('scaler', StandardScaler())                   # Then scale the data\n",
    "])\n",
    "\n",
    "# Step 3: Fit and transform the data using the pipeline\n",
    "clean_scaled_data = pipeline.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame for easy viewing\n",
    "clean_scaled_df = pd.DataFrame(clean_scaled_data, columns=df.columns)\n",
    "\n",
    "print(\"\\nData after Imputation and Scaling:\")\n",
    "print(clean_scaled_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
