{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 5: Label Encoding vs One-Hot Encoding on 'sex'\n",
      "Label Encoded 'sex' values:\n",
      "      sex  sex_encoded\n",
      "0    male            1\n",
      "1  female            0\n",
      "2  female            0\n",
      "3  female            0\n",
      "4    male            1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_le[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# One-Hot Encoding (creates separate binary columns)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m ohe \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# drop first to avoid dummy variable trap\u001b[39;00m\n\u001b[1;32m     36\u001b[0m X_ohe \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     37\u001b[0m sex_ohe \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mfit_transform(X_ohe[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset (using seaborn for easy access)\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Select subset and drop rows with missing values for simplicity\n",
    "titanic = titanic[['sex', 'embarked', 'pclass', 'fare', 'age', 'survived']].dropna()\n",
    "\n",
    "# Features and target\n",
    "X = titanic.drop('survived', axis=1)\n",
    "y = titanic['survived']\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 5: Label Encoding vs One-Hot Encoding on 'sex'\n",
    "print(\"\\nQuestion 5: Label Encoding vs One-Hot Encoding on 'sex'\")\n",
    "\n",
    "# Label Encoding (converts categories to integers)\n",
    "le = LabelEncoder()\n",
    "X_le = X.copy()\n",
    "X_le['sex_encoded'] = le.fit_transform(X_le['sex'])\n",
    "print(\"Label Encoded 'sex' values:\")\n",
    "print(X_le[['sex', 'sex_encoded']].head())\n",
    "\n",
    "# One-Hot Encoding (creates separate binary columns)\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')  # drop first to avoid dummy variable trap\n",
    "X_ohe = X.copy()\n",
    "sex_ohe = ohe.fit_transform(X_ohe[['sex']])\n",
    "sex_ohe_df = pd.DataFrame(sex_ohe, columns=ohe.get_feature_names_out(['sex']), index=X_ohe.index)\n",
    "X_ohe = pd.concat([X_ohe, sex_ohe_df], axis=1)\n",
    "print(\"\\nOne-Hot Encoded 'sex' columns:\")\n",
    "print(X_ohe[['sex', 'sex_male']].head())  # 'sex_male' is one-hot encoded column\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 6: Combining Min-Max Scaling and Standardization\n",
    "print(\"\\nQuestion 6: Combining Min-Max Scaling and Standardization\")\n",
    "\n",
    "# Example: First Min-Max scaling, then Standardization on 'fare' and 'age'\n",
    "\n",
    "# Step 1: Min-Max scaling\n",
    "minmax = MinMaxScaler()\n",
    "X_scaled_minmax = X[['fare', 'age']].copy()\n",
    "X_scaled_minmax = pd.DataFrame(minmax.fit_transform(X_scaled_minmax), columns=['fare', 'age'])\n",
    "\n",
    "# Step 2: Standardization of Min-Max scaled data\n",
    "std = StandardScaler()\n",
    "X_scaled_combined = pd.DataFrame(std.fit_transform(X_scaled_minmax), columns=['fare', 'age'])\n",
    "\n",
    "print(\"Original 'fare' and 'age' stats:\")\n",
    "print(X[['fare', 'age']].describe().loc[['min', 'max', 'mean', 'std']])\n",
    "print(\"\\nAfter Min-Max Scaling:\")\n",
    "print(X_scaled_minmax.describe().loc[['min', 'max', 'mean', 'std']])\n",
    "print(\"\\nAfter Standardization of Min-Max scaled data:\")\n",
    "print(X_scaled_combined.describe().loc[['min', 'max', 'mean', 'std']])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 7: Handling multiple categorical features with One-Hot Encoding ('sex', 'embarked')\n",
    "print(\"\\nQuestion 7: One-Hot Encoding 'sex' and 'embarked'\")\n",
    "\n",
    "# Use pandas get_dummies for simplicity, drop first to avoid dummy variable trap\n",
    "X_ohe_multi = pd.get_dummies(X, columns=['sex', 'embarked'], drop_first=True)\n",
    "print(X_ohe_multi.head())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 8: Ordinal Encoding for 'pclass' (Passenger class)\n",
    "print(\"\\nQuestion 8: Ordinal Encoding of 'pclass'\")\n",
    "\n",
    "# Since 'pclass' is already ordinal with ranks 1 (first) < 2 (second) < 3 (third),\n",
    "# map it explicitly or use OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(categories=[[1, 2, 3]])\n",
    "X_ordinal = X.copy()\n",
    "X_ordinal['pclass_encoded'] = ordinal_encoder.fit_transform(X_ordinal[['pclass']])\n",
    "print(X_ordinal[['pclass', 'pclass_encoded']].head())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 9: Impact of Scaling on Decision Tree vs SVM\n",
    "\n",
    "print(\"\\nQuestion 9: Impact of Scaling on Decision Tree vs SVM\")\n",
    "\n",
    "# Split data for modeling\n",
    "X_model = X_ohe_multi.copy()  # Use one-hot encoded features for simplicity\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_model, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Decision Tree (tree-based models are NOT sensitive to feature scaling)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "print(f\"Decision Tree Accuracy (no scaling needed): {accuracy_score(y_test, dt_pred):.4f}\")\n",
    "\n",
    "# SVM WITHOUT scaling\n",
    "svm_no_scale = SVC(random_state=42)\n",
    "svm_no_scale.fit(X_train, y_train)\n",
    "svm_pred_no_scale = svm_no_scale.predict(X_test)\n",
    "print(f\"SVM Accuracy without scaling: {accuracy_score(y_test, svm_pred_no_scale):.4f}\")\n",
    "\n",
    "# SVM WITH scaling (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_scaled = SVC(random_state=42)\n",
    "svm_scaled.fit(X_train_scaled, y_train)\n",
    "svm_pred_scaled = svm_scaled.predict(X_test_scaled)\n",
    "print(f\"SVM Accuracy with Standard Scaling: {accuracy_score(y_test, svm_pred_scaled):.4f}\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Question 10: Custom Transformation Function for High Cardinality Categorical Features\n",
    "\n",
    "print(\"\\nQuestion 10: Custom Encoding for High Cardinality Features\")\n",
    "\n",
    "# Example: Frequency encoding for a categorical feature (simulate with 'embarked')\n",
    "\n",
    "def frequency_encoding(series):\n",
    "    freq = series.value_counts(normalize=True)\n",
    "    return series.map(freq)\n",
    "\n",
    "# Apply frequency encoding to 'embarked'\n",
    "X_freq_encoded = X.copy()\n",
    "X_freq_encoded['embarked_freq'] = frequency_encoding(X_freq_encoded['embarked'])\n",
    "print(X_freq_encoded[['embarked', 'embarked_freq']].head())\n",
    "\n",
    "# Frequency encoding helps preserve information with fewer dimensions compared to one-hot encoding\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
