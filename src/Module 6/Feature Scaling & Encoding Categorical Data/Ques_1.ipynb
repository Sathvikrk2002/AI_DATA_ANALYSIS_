{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Feature Scaling\n",
      "\n",
      "Feature scaling is essential because many machine learning algorithms compute distances (e.g., KNN, SVM) \n",
      "or rely on gradient-based optimization (e.g., Logistic Regression, Neural Networks). \n",
      "Features with larger numeric ranges can dominate the objective function, causing models to perform poorly.\n",
      "\n",
      "Without scaling, features on different scales cause the model to bias towards variables with larger values.\n",
      "\n",
      "Below is a demonstration using Logistic Regression on the Iris dataset with and without scaling.\n",
      "\n",
      "Accuracy WITHOUT feature scaling: 0.9474\n",
      "\n",
      "Question 2: Min-Max Scaling\n",
      "Accuracy WITH Min-Max scaling: 0.8684\n",
      "\n",
      "Question 3: Standardization (Z-score Scaling)\n",
      "Accuracy WITH Standardization (Z-score): 0.9211\n",
      "\n",
      "Question 4: Robust Scaling\n",
      "Accuracy WITH Robust scaling: 0.8684\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Question 1: Feature Scaling Explanation and Demonstration\n",
    "print(\"Question 1: Feature Scaling\")\n",
    "print(\"\"\"\n",
    "Feature scaling is essential because many machine learning algorithms compute distances (e.g., KNN, SVM) \n",
    "or rely on gradient-based optimization (e.g., Logistic Regression, Neural Networks). \n",
    "Features with larger numeric ranges can dominate the objective function, causing models to perform poorly.\n",
    "\n",
    "Without scaling, features on different scales cause the model to bias towards variables with larger values.\n",
    "\n",
    "Below is a demonstration using Logistic Regression on the Iris dataset with and without scaling.\n",
    "\"\"\")\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Train logistic regression WITHOUT scaling\n",
    "model_unscaled = LogisticRegression(max_iter=200)\n",
    "model_unscaled.fit(X_train, y_train)\n",
    "pred_unscaled = model_unscaled.predict(X_test)\n",
    "acc_unscaled = accuracy_score(y_test, pred_unscaled)\n",
    "\n",
    "print(f\"Accuracy WITHOUT feature scaling: {acc_unscaled:.4f}\")\n",
    "\n",
    "# Question 2: Min-Max Scaling\n",
    "print(\"\\nQuestion 2: Min-Max Scaling\")\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_minmax = minmax_scaler.fit_transform(X_train)\n",
    "X_test_minmax = minmax_scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression with Min-Max scaled data\n",
    "model_minmax = LogisticRegression(max_iter=200)\n",
    "model_minmax.fit(X_train_minmax, y_train)\n",
    "pred_minmax = model_minmax.predict(X_test_minmax)\n",
    "acc_minmax = accuracy_score(y_test, pred_minmax)\n",
    "\n",
    "print(f\"Accuracy WITH Min-Max scaling: {acc_minmax:.4f}\")\n",
    "\n",
    "# Question 3: Standardization (Z-score Scaling)\n",
    "print(\"\\nQuestion 3: Standardization (Z-score Scaling)\")\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_std = standard_scaler.fit_transform(X_train)\n",
    "X_test_std = standard_scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression with standardized data\n",
    "model_std = LogisticRegression(max_iter=200)\n",
    "model_std.fit(X_train_std, y_train)\n",
    "pred_std = model_std.predict(X_test_std)\n",
    "acc_std = accuracy_score(y_test, pred_std)\n",
    "\n",
    "print(f\"Accuracy WITH Standardization (Z-score): {acc_std:.4f}\")\n",
    "\n",
    "# Question 4: Robust Scaling\n",
    "print(\"\\nQuestion 4: Robust Scaling\")\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_robust = robust_scaler.fit_transform(X_train)\n",
    "X_test_robust = robust_scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression with robust scaled data\n",
    "model_robust = LogisticRegression(max_iter=200)\n",
    "model_robust.fit(X_train_robust, y_train)\n",
    "pred_robust = model_robust.predict(X_test_robust)\n",
    "acc_robust = accuracy_score(y_test, pred_robust)\n",
    "\n",
    "print(f\"Accuracy WITH Robust scaling: {acc_robust:.4f}\")\n",
    "\n",
    "# Bonus: Visual comparison of feature distributions before and after scaling\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 12))\n",
    "\n",
    "axs[0].hist(X_train[:, 0], bins=20, color='blue', alpha=0.7)\n",
    "axs[0].set_title(\"Original Feature (sepal length) Distribution\")\n",
    "\n",
    "axs[1].hist(X_train_minmax[:, 0], bins=20, color='green', alpha=0.7)\n",
    "axs[1].set_title(\"Min-Max Scaled Feature Distribution\")\n",
    "\n",
    "axs[2].hist(X_train_std[:, 0], bins=20, color='red', alpha=0.7)\n",
    "axs[2].set_title(\"Standardized (Z-score) Feature Distribution\")\n",
    "\n",
    "axs[3].hist(X_train_robust[:, 0], bins=20, color='purple', alpha=0.7)\n",
    "axs[3].set_title(\"Robust Scaled Feature Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
