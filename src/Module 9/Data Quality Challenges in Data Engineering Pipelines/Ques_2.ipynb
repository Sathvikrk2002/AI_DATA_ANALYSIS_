{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Handling Schema Mismatches using Spark\n",
    "**Description**: Use Apache Spark to address schema mismatches by transforming data to match\n",
    "the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Create Spark session\n",
    "2. Load dataframe\n",
    "3. Define the expected schema\n",
    "4. Handle schema mismatches\n",
    "5. Show corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StructType, StructField, StringType, IntegerType\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step 1: Create Spark session\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Step 1: Create Spark session\n",
    "spark = SparkSession.builder.appName(\"SchemaMismatchHandling\").getOrCreate()\n",
    "\n",
    "# Step 2: Load dataframe (simulate with sample data having schema issues)\n",
    "data = [\n",
    "    (\"1\", \"John Doe\", \"18\", \"A\"),\n",
    "    (\"2\", \"Jane Smith\", \"22\", \"B\"),\n",
    "    (\"3\", \"Bob Johnson\", \"seventeen\", \"C\"),  # Age is a string word\n",
    "    (\"4\", \"Alice Brown\", None, \"E\"),         # Missing age\n",
    "    (\"5\", \"Tom White\", \"15\", None)           # Missing grade\n",
    "]\n",
    "\n",
    "# Create DataFrame with inferred schema (potential mismatches)\n",
    "df_raw = spark.createDataFrame(data, [\"ID\", \"Name\", \"Age\", \"Grade\"])\n",
    "print(\"Raw Data (Before Schema Correction):\")\n",
    "df_raw.show()\n",
    "\n",
    "# Step 3: Define the expected schema\n",
    "expected_schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Grade\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Step 4: Handle schema mismatches\n",
    "# Convert data types using casting and handle errors\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_corrected = df_raw \\\n",
    "    .withColumn(\"ID\", col(\"ID\").cast(\"int\")) \\\n",
    "    .withColumn(\"Age\", col(\"Age\").cast(\"int\")) \\\n",
    "    .withColumn(\"Grade\", col(\"Grade\").cast(\"string\"))\n",
    "\n",
    "print(\"Corrected Data (After Schema Handling):\")\n",
    "df_corrected.show()\n",
    "\n",
    "# Optional: Validate schema\n",
    "print(\"Corrected Schema:\")\n",
    "df_corrected.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Detect and Correct Incomplete Data in ETL\n",
    "**Description**: Use Python and Pandas to detect incomplete data in an ETL process and fill\n",
    "missing values with estimates.\n",
    "\n",
    "**Steps**:\n",
    "1. Detect incomplete data\n",
    "2. Fill missing values\n",
    "3. Report changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   ID  Name   Age Grade\n",
      "0   1  John  18.0     A\n",
      "1   2  Jane   NaN     B\n",
      "2   3   Bob  17.0  None\n",
      "3   4  None  20.0     C\n",
      "4   5   Eva   NaN     A\n",
      "\n",
      "Missing Values Count:\n",
      "ID       0\n",
      "Name     1\n",
      "Age      2\n",
      "Grade    1\n",
      "dtype: int64\n",
      "\n",
      "Cleaned Data:\n",
      "   ID     Name        Age Grade\n",
      "0   1     John  18.000000     A\n",
      "1   2     Jane  18.333333     B\n",
      "2   3      Bob  17.000000     A\n",
      "3   4  Unknown  20.000000     C\n",
      "4   5      Eva  18.333333     A\n",
      "\n",
      "Summary of Changes:\n",
      "Missing 'Name' filled with 'Unknown'\n",
      "Missing 'Age' filled with mean age: 18.33\n",
      "Missing 'Grade' filled with mode: A\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sample data simulating an ETL load with missing values\n",
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5],\n",
    "    'Name': ['John', 'Jane', 'Bob', None, 'Eva'],\n",
    "    'Age': [18, None, 17, 20, None],\n",
    "    'Grade': ['A', 'B', None, 'C', 'A']\n",
    "}\n",
    "\n",
    "# Step 1: Detect incomplete data\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 2: Fill missing values with estimates\n",
    "# Fill missing Name with \"Unknown\"\n",
    "df['Name'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Fill missing Age with mean age\n",
    "mean_age = df['Age'].mean()\n",
    "df['Age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# Fill missing Grade with mode\n",
    "mode_grade = df['Grade'].mode()[0]\n",
    "df['Grade'].fillna(mode_grade, inplace=True)\n",
    "\n",
    "# Step 3: Report changes\n",
    "print(\"\\nCleaned Data:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nSummary of Changes:\")\n",
    "print(f\"Missing 'Name' filled with 'Unknown'\")\n",
    "print(f\"Missing 'Age' filled with mean age: {mean_age:.2f}\")\n",
    "print(f\"Missing 'Grade' filled with mode: {mode_grade}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
