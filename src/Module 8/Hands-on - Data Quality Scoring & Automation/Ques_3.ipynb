{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate Data Quality Checks with Great Expectations\n",
    "**Introduction**: In this activity, you will learn how to automate data quality checks using the Great Expectations framework. This includes setting up expectations and generating validation reports.\n",
    "\n",
    "### Task 1: Setup and Initial Expectations\n",
    "\n",
    "1. Objective: Set up Great Expectations and create initial expectations for a dataset.\n",
    "2. Steps:\n",
    "    - Install Great Expectations using pip.\n",
    "    - Initialize a data context.\n",
    "    - Create basic expectations on a sample dataset.\n",
    "    - Eg., Implement a basic setup and expectation for column presence and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/my_ge_project\n",
      "Great Expectations project will be created at: /workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/my_ge_project/my_ge_project_jupyter\n",
      "Creating project directory: /workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/my_ge_project/my_ge_project_jupyter\n",
      "\n",
      "--- 1. Create Sample Dataset ---\n",
      "Sample data created at: /workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/my_ge_project/my_ge_project_jupyter/data/sample_data.csv\n",
      "Sample Data Preview:\n",
      "   id     name  age           city\n",
      "0   1    Alice   30       New York\n",
      "1   2      Bob   24    Los Angeles\n",
      "2   3  Charlie   35        Chicago\n",
      "3   4    David   29       New York\n",
      "4   5      Eve   42  San Francisco\n",
      "\n",
      "--- 2. Initialize Great Expectations Data Context (Interactive Step) ---\n",
      "Please run the following command in a new terminal within your Jupyter environment:\n",
      "cd /workspaces/AI_DATA_ANALYSIS_/src/Module 8/Hands-on - Data Quality Scoring & Automation/my_ge_project/my_ge_project_jupyter\n",
      "great_expectations init\n",
      "\n",
      "When prompted, type 'y' and press Enter.\n",
      "\n",
      "--- AFTER INITIALIZATION, CONTINUE IN THE NOTEBOOK ---\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Datasets and Generate Reports\n",
    "\n",
    "1. Objective: Validate a dataset against defined expectations and generate a report.\n",
    "2. Steps:\n",
    "    - Execute the validation process on the dataset.\n",
    "    - Review the validation results and generate a report.\n",
    "    - Eg., Validate completeness and consistency expectations, and view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchRequest\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Checkpoint\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from great_expectations.data_context import DataContext\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.checkpoint import Checkpoint\n",
    "\n",
    "# --- Configuration (ensure these match your Task 1 setup) ---\n",
    "PROJECT_DIR_NAME = \"my_ge_project_jupyter\"\n",
    "GE_PROJECT_PATH = os.path.join(os.getcwd(), PROJECT_DIR_NAME) # Assuming you are in the notebook's original root\n",
    "DATA_DIR_NAME = \"data\"\n",
    "SAMPLE_DATA_FILE_PATH = os.path.join(GE_PROJECT_PATH, DATA_DIR_NAME, \"sample_data.csv\")\n",
    "EXPECTATION_SUITE_NAME = \"my_sample_data_expectations\"\n",
    "\n",
    "# --- Ensure we are in the correct directory for DataContext to load ---\n",
    "# This is crucial if you ran previous cells and moved directories or restarted kernel\n",
    "if os.getcwd() != GE_PROJECT_PATH:\n",
    "    print(f\"Changing current working directory to: {GE_PROJECT_PATH}\")\n",
    "    os.chdir(GE_PROJECT_PATH)\n",
    "else:\n",
    "    print(f\"Already in the correct directory: {os.getcwd()}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Task 2: Validate Datasets and Generate Reports ---\")\n",
    "\n",
    "print(\"\\n--- 1. Objective: Validate a dataset against defined expectations and generate a report. ---\")\n",
    "\n",
    "# Load the DataContext. This assumes `great_expectations init` was run and the GE directory exists.\n",
    "context = DataContext()\n",
    "print(\"Great Expectations DataContext loaded.\")\n",
    "\n",
    "# Define the batch request to identify the data to be validated\n",
    "batch_request = BatchRequest(\n",
    "    datasource_name=\"my_sample_data_source\",\n",
    "    data_connector_name=\"default_inferred_data_connector\",\n",
    "    data_asset_name=\"sample_data\",\n",
    "    # Path is relative to the base_directory configured for the data connector\n",
    "    batch_spec_passthrough={\"path\": \"sample_data.csv\"}\n",
    ")\n",
    "\n",
    "print(f\"\\nAttempting to validate data asset: {batch_request.data_asset_name}\")\n",
    "print(f\"Using expectation suite: {EXPECTATION_SUITE_NAME}\")\n",
    "\n",
    "# --- 2. Execute the validation process on the dataset. ---\n",
    "\n",
    "# Great Expectations often uses Checkpoints for validation workflows.\n",
    "# Let's create a simple in-memory Checkpoint for this validation.\n",
    "# In a production setup, you would define Checkpoints in great_expectations/checkpoints/\n",
    "\n",
    "checkpoint_config = {\n",
    "    \"name\": \"my_sample_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"run_name_template\": \"%Y%m%d-%H%M%S-validation\", # A template for naming validation runs\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": EXPECTATION_SUITE_NAME,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add the checkpoint to the context (it will be saved to your great_expectations/checkpoints directory)\n",
    "context.add_checkpoint(**checkpoint_config)\n",
    "print(\"Checkpoint 'my_sample_checkpoint' added to DataContext.\")\n",
    "\n",
    "# Get the checkpoint and run the validation\n",
    "checkpoint = context.get_checkpoint(name=\"my_sample_checkpoint\")\n",
    "checkpoint_result = checkpoint.run()\n",
    "\n",
    "print(\"\\n--- Validation Execution Complete ---\")\n",
    "print(f\"Validation successful: {checkpoint_result.success}\")\n",
    "print(f\"Number of expectations run: {checkpoint_result.statistics['evaluated_expectations']}\")\n",
    "print(f\"Number of expectations passed: {checkpoint_result.statistics['successful_expectations']}\")\n",
    "print(f\"Number of expectations failed: {checkpoint_result.statistics['unsuccessful_expectations']}\")\n",
    "\n",
    "\n",
    "# --- 3. Review the validation results and generate a report. ---\n",
    "# The build_data_docs() method automatically generates HTML reports from validation results.\n",
    "# It picks up the results from your latest validation runs.\n",
    "\n",
    "print(\"\\n--- Generating Data Docs to review results ---\")\n",
    "context.build_data_docs()\n",
    "print(\"Data Docs built successfully.\")\n",
    "\n",
    "# Get the path to the latest data docs index.html\n",
    "data_docs_path = os.path.abspath(os.path.join('great_expectations', 'uncommitted', 'data_docs', 'index.html'))\n",
    "print(f\"To view the validation report, open this file in your web browser: {data_docs_path}\")\n",
    "\n",
    "# Optional: Add more specific expectations to demonstrate validation failures\n",
    "# For example, let's create a slightly modified dataset that might fail some checks\n",
    "print(\"\\n--- Optional: Demonstrating Validation Failures ---\")\n",
    "print(\"Creating a 'bad_sample_data.csv' to show failed expectations.\")\n",
    "bad_data = {\n",
    "    'id': [1, 'two', 3, 4, 5], # 'two' is wrong type\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [30, 24, 35, None, 42], # None is missing value (will be float)\n",
    "    'city': ['New York', 'Los Angeles', 'Chicago', 'New York', 'San Francisco', 'Extra City'] # Extra column for match_set failure (if schema check were stricter)\n",
    "}\n",
    "bad_df = pd.DataFrame(bad_data)\n",
    "bad_sample_data_file_path = os.path.join(GE_PROJECT_PATH, DATA_DIR_NAME, \"bad_sample_data.csv\")\n",
    "bad_df.to_csv(bad_sample_data_file_path, index=False)\n",
    "print(f\"Bad sample data created at: {bad_sample_data_file_path}\")\n",
    "\n",
    "# Define a new batch request for the bad data\n",
    "bad_batch_request = BatchRequest(\n",
    "    datasource_name=\"my_sample_data_source\",\n",
    "    data_connector_name=\"default_inferred_data_connector\",\n",
    "    data_asset_name=\"bad_sample_data\", # New data asset name\n",
    "    batch_spec_passthrough={\"path\": \"bad_sample_data.csv\"}\n",
    ")\n",
    "\n",
    "# Create a new checkpoint for the bad data validation\n",
    "bad_checkpoint_config = {\n",
    "    \"name\": \"my_bad_data_checkpoint\",\n",
    "    \"config_version\": 1,\n",
    "    \"class_name\": \"SimpleCheckpoint\",\n",
    "    \"run_name_template\": \"%Y%m%d-%H%M%S-bad-validation\",\n",
    "    \"validations\": [\n",
    "        {\n",
    "            \"batch_request\": bad_batch_request,\n",
    "            \"expectation_suite_name\": EXPECTATION_SUITE_NAME, # Using the same suite\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "context.add_checkpoint(**bad_checkpoint_config)\n",
    "print(\"Checkpoint 'my_bad_data_checkpoint' added for bad data validation.\")\n",
    "\n",
    "bad_checkpoint = context.get_checkpoint(name=\"my_bad_data_checkpoint\")\n",
    "bad_checkpoint_result = bad_checkpoint.run()\n",
    "\n",
    "print(\"\\n--- Bad Data Validation Execution Complete ---\")\n",
    "print(f\"Validation successful: {bad_checkpoint_result.success}\") # Should be False\n",
    "print(f\"Number of expectations run: {bad_checkpoint_result.statistics['evaluated_expectations']}\")\n",
    "print(f\"Number of expectations passed: {bad_checkpoint_result.statistics['successful_expectations']}\")\n",
    "print(f\"Number of expectations failed: {bad_checkpoint_result.statistics['unsuccessful_expectations']}\")\n",
    "\n",
    "print(\"\\n--- Re-generating Data Docs to see new validation results (including failures) ---\")\n",
    "context.build_data_docs()\n",
    "print(\"Data Docs re-built successfully. Check the report for failed expectations on 'bad_sample_data'.\")\n",
    "print(f\"Re-open this path to view updated Data Docs: {data_docs_path}\")\n",
    "\n",
    "print(\"\\n--- Task 2 Complete! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Advanced Expectations and Scheduling\n",
    "\n",
    "1. Objective: Create advanced expectations for conditional checks and automate the validation.\n",
    "2. Steps:\n",
    "    - Define advanced expectations based on complex conditions.\n",
    "    - Use scheduling tools to automate periodic checks.\n",
    "    - E.g., an expectation that customer IDs must be unique and schedule a daily check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
