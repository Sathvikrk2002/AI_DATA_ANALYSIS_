{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created reference_data.csv\n",
      "Loaded sample_data.csv and reference_data.csv\n",
      "\n",
      "Task 1: Completeness Score\n",
      "Completeness per column (% non-missing):\n",
      "Name      66.666667\n",
      "Email    100.000000\n",
      "Age       83.333333\n",
      "dtype: float64\n",
      "Overall Completeness Score: 83.33%\n",
      "\n",
      "Task 2: Accuracy Score\n",
      "Email matches: 3/4\n",
      "Age matches: 3/4\n",
      "Accuracy Score: 75.00%\n",
      "\n",
      "Task 3: Consistency Score\n",
      "Consistent Emails: 5/6\n",
      "Consistency Score: 83.33%\n",
      "\n",
      "Initialized Great Expectations DataContext\n",
      "Error setting up datasource/asset: 'FileDataContext' object has no attribute 'datasources'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FileDataContext' object has no attribute 'datasources'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m data_asset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m datasource_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasources\u001b[49m:\n\u001b[1;32m    104\u001b[0m         datasource \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39msources\u001b[38;5;241m.\u001b[39madd_pandas(name\u001b[38;5;241m=\u001b[39mdatasource_name)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FileDataContext' object has no attribute 'datasources'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import FileDataContext\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Step 1: Create sample_data.csv and reference_data.csv if they don't exist\n",
    "if not os.path.exists('sample_data.csv'):\n",
    "    data = {\n",
    "        'Name': ['Alice', 'Bob', '', 'David', 'Eve', None],\n",
    "        'Email': ['alice@example.com', 'bob@example', 'charlie@domain.com', 'david@example.com', 'eve@example.com', 'eve@example.com'],\n",
    "        'Age': [25, None, 30, 28, 22, 35]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('sample_data.csv', index=False)\n",
    "    print(\"Created sample_data.csv\")\n",
    "\n",
    "if not os.path.exists('reference_data.csv'):\n",
    "    ref_data = {\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'Email': ['alice@example.com', 'bob@domain.com', 'charlie@domain.com', 'david@example.com', 'eve@example.com'],\n",
    "        'Age': [25, 27, 30, 28, 22]\n",
    "    }\n",
    "    ref_df = pd.DataFrame(ref_data)\n",
    "    ref_df.to_csv('reference_data.csv', index=False)\n",
    "    print(\"Created reference_data.csv\")\n",
    "\n",
    "# Step 2: Load datasets\n",
    "try:\n",
    "    df = pd.read_csv('sample_data.csv')\n",
    "    ref_df = pd.read_csv('reference_data.csv')\n",
    "    print(\"Loaded sample_data.csv and reference_data.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading datasets: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 3: Task 1 - Completeness Score\n",
    "try:\n",
    "    # Calculate percentage of non-missing values for each column\n",
    "    completeness_per_column = df.notnull().mean() * 100\n",
    "    completeness_score = completeness_per_column.mean()\n",
    "    print(\"\\nTask 1: Completeness Score\")\n",
    "    print(\"Completeness per column (% non-missing):\")\n",
    "    print(completeness_per_column)\n",
    "    print(f\"Overall Completeness Score: {completeness_score:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating completeness score: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 4: Task 2 - Accuracy Score\n",
    "try:\n",
    "    # Merge datasets on Name for comparison\n",
    "    merged_df = df.merge(ref_df, on='Name', how='inner', suffixes=('_main', '_ref'))\n",
    "    \n",
    "    # Compare Email and Age columns\n",
    "    email_matches = (merged_df['Email_main'] == merged_df['Email_ref']).sum()\n",
    "    age_matches = (merged_df['Age_main'] == merged_df['Age_ref']).sum()\n",
    "    \n",
    "    total_comparisons = len(merged_df) * 2  # Two columns compared\n",
    "    matches = email_matches + age_matches\n",
    "    accuracy_score = (matches / total_comparisons) * 100 if total_comparisons > 0 else 0\n",
    "    \n",
    "    print(\"\\nTask 2: Accuracy Score\")\n",
    "    print(f\"Email matches: {email_matches}/{len(merged_df)}\")\n",
    "    print(f\"Age matches: {age_matches}/{len(merged_df)}\")\n",
    "    print(f\"Accuracy Score: {accuracy_score:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating accuracy score: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 5: Task 3 - Consistency Score\n",
    "try:\n",
    "    # Check if Email follows consistent format (contains '@' and '.')\n",
    "    def is_consistent_email(email):\n",
    "        if pd.isna(email):\n",
    "            return False\n",
    "        return bool(re.match(r'^.+@.+\\..+$', str(email)))\n",
    "    \n",
    "    consistent_emails = df['Email'].apply(is_consistent_email).sum()\n",
    "    total_emails = df['Email'].count()\n",
    "    consistency_score = (consistent_emails / total_emails) * 100 if total_emails > 0 else 0\n",
    "    \n",
    "    print(\"\\nTask 3: Consistency Score\")\n",
    "    print(f\"Consistent Emails: {consistent_emails}/{total_emails}\")\n",
    "    print(f\"Consistency Score: {consistency_score:.2f}%\")\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating consistency score: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 6: Initialize Great Expectations DataContext\n",
    "try:\n",
    "    context = FileDataContext(project_root_dir=\".\")\n",
    "    print(\"\\nInitialized Great Expectations DataContext\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing DataContext: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 7: Set up Datasource and Data Asset\n",
    "datasource_name = \"pandas_datasource\"\n",
    "data_asset_name = \"sample_data\"\n",
    "\n",
    "try:\n",
    "    if datasource_name not in context.datasources:\n",
    "        datasource = context.sources.add_pandas(name=datasource_name)\n",
    "    else:\n",
    "        datasource = context.datasources[datasource_name]\n",
    "    \n",
    "    if data_asset_name not in [asset.name for asset in datasource.get_asset_names()]:\n",
    "        data_asset = datasource.add_csv_asset(name=data_asset_name, filepath_or_buffer=\"sample_data.csv\")\n",
    "    else:\n",
    "        data_asset = datasource.get_asset(data_asset_name)\n",
    "    print(f\"Verified datasource '{datasource_name}' and asset '{data_asset_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting up datasource/asset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 8: Create or Load Expectation Suite\n",
    "suite_name = \"sample_data_suite\"\n",
    "try:\n",
    "    if suite_name not in context.list_expectation_suite_names():\n",
    "        suite = context.add_expectation_suite(expectation_suite_name=suite_name)\n",
    "    else:\n",
    "        suite = context.get_expectation_suite(expectation_suite_name=suite_name)\n",
    "    print(f\"Expectation suite '{suite_name}' ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating/loading expectation suite: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 9: Define Expectations (update suite with completeness and consistency)\n",
    "try:\n",
    "    batch_request = data_asset.build_batch_request()\n",
    "    validator = context.get_validator(batch_request=batch_request, expectation_suite_name=suite_name)\n",
    "    \n",
    "    # Completeness expectations\n",
    "    validator.expect_column_values_to_not_be_null(column=\"Email\", mostly=0.95, result_format=\"SUMMARY\")\n",
    "    validator.expect_column_values_to_not_be_null(column=\"Name\", mostly=0.80, result_format=\"SUMMARY\")\n",
    "    validator.expect_column_values_to_not_be_null(column=\"Age\", mostly=0.80, result_format=\"SUMMARY\")\n",
    "    \n",
    "    # Consistency expectation for Email format\n",
    "    validator.expect_column_values_to_match_regex(\n",
    "        column=\"Email\",\n",
    "        regex=r'^.+@.+\\..+$',\n",
    "        mostly=0.95,\n",
    "        result_format=\"SUMMARY\"\n",
    "    )\n",
    "    \n",
    "    validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "    print(\"Updated expectation suite with completeness and consistency expectations\")\n",
    "except Exception as e:\n",
    "    print(f\"Error defining expectations: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 10: Run Validation\n",
    "try:\n",
    "    checkpoint = context.add_or_update_checkpoint(\n",
    "        name=\"sample_checkpoint\",\n",
    "        validations=[\n",
    "            {\n",
    "                \"batch_request\": batch_request,\n",
    "                \"expectation_suite_name\": suite_name,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    checkpoint_result = checkpoint.run()\n",
    "    print(\"\\nValidation completed\")\n",
    "except Exception as e:\n",
    "    print(f\"Error running validation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 11: Store Metrics in Context\n",
    "try:\n",
    "    context.variables.metadata = {\n",
    "        \"completeness_score\": f\"{completeness_score:.2f}%\",\n",
    "        \"accuracy_score\": f\"{accuracy_score:.2f}%\",\n",
    "        \"consistency_score\": f\"{consistency_score:.2f}%\"\n",
    "    }\n",
    "    context.save_context()\n",
    "    print(\"Stored metrics in DataContext\")\n",
    "except Exception as e:\n",
    "    print(f\"Error storing metrics: {e}\")\n",
    "    raise\n",
    "\n",
    "# Step 12: Generate HTML Report\n",
    "try:\n",
    "    context.build_data_docs()\n",
    "    print(\"\\nHTML report generated in the Great Expectations Data Docs directory\")\n",
    "    \n",
    "    report_path = \"data_quality_scores_report.html\"\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(context.get_data_docs_page(checkpoint_result))\n",
    "    print(f\"HTML report saved to '{report_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating HTML report: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
